---
BiGDRP:
  learning_rate: 1e-5
  num_epoch: 1
  batch_size: 128
  common_dim: 512
  expr_enc: 1024
  conv_layers:
    - conv1: 512
    - conv2: 512
  mid: 512
  drop:
    - 0.2
    - 0.5

